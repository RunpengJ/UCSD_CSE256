import torch
import torch.nn as nn

class Head(nn.Module):
    def __init__(self, ):
        None


class MultiHeadAttention(nn.Module):
    def __init__(self, embed_dim, ) -> None:
        super().__init__()
        None